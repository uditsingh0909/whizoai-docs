---
title: "Search API"
api: "POST https://api.whizo.ai/v1/search"
description: "Search the web and optionally scrape content from search results"
---

The Search API combines web search functionality with content scraping capabilities. Search for any query and optionally scrape the full content from each search result in a single API call.

## Authentication

<ParamField header="Authorization" type="string" required>
  Bearer token using your API key: `Bearer YOUR_API_KEY`
</ParamField>

## Request Body

<ParamField body="query" type="string" required>
  The search query string (1-500 characters)
</ParamField>

<ParamField body="limit" type="number" default="10">
  Maximum number of search results to return (1-20)
</ParamField>

<ParamField body="country" type="string">
  ISO country code for localized search results (e.g., "US", "GB", "JP")
</ParamField>

<ParamField body="language" type="string">
  Language code for search results (e.g., "en", "es", "fr")
</ParamField>

<ParamField body="provider" type="string">
  Search provider to use:
  - `google` - Google Search (default)
  - `ollama` - Alternative search provider
</ParamField>

<ParamField body="scrapeResults" type="boolean" default="false">
  Whether to scrape full content from each search result (+1 credit per result)
</ParamField>

<ParamField body="scrapeOptions" type="object">
  Configuration for scraping search results (only applies if scrapeResults=true)
  <Expandable title="scrapeOptions properties">
    <ParamField body="scrapeOptions.format" type="string" default="markdown">
      Output format for scraped content:
      - `markdown` - Clean markdown format
      - `html` - HTML content
      - `text` - Plain text only
      - `json` - Structured JSON
      - `structured` - AI-enhanced structured data
    </ParamField>

    <ParamField body="scrapeOptions.includeScreenshot" type="boolean" default="false">
      Capture screenshot of each search result page
    </ParamField>

    <ParamField body="scrapeOptions.mobile" type="boolean" default="false">
      Use mobile viewport when scraping
    </ParamField>

    <ParamField body="scrapeOptions.extractionSchema" type="object">
      JSON schema for AI-powered data extraction from search results
    </ParamField>

    <ParamField body="scrapeOptions.maxAge" type="number" default="30">
      Cache max age in days (1-365)
    </ParamField>
  </Expandable>
</ParamField>

## Response

<ResponseField name="success" type="boolean">
  Indicates if the request was successful
</ResponseField>

<ResponseField name="data" type="object">
  <Expandable title="data properties">
    <ResponseField name="query" type="string">
      The search query that was executed
    </ResponseField>

    <ResponseField name="results" type="array">
      Array of search results
      <Expandable title="result properties">
        <ResponseField name="position" type="number">
          Position in search results (1-based)
        </ResponseField>

        <ResponseField name="title" type="string">
          Search result title
        </ResponseField>

        <ResponseField name="link" type="string">
          URL of the search result
        </ResponseField>

        <ResponseField name="snippet" type="string">
          Search result snippet/description
        </ResponseField>

        <ResponseField name="displayLink" type="string">
          Display URL shown in search results
        </ResponseField>

        <ResponseField name="sitelinks" type="array" optional>
          Additional sitelinks from the search result
        </ResponseField>

        <ResponseField name="content" type="string" optional>
          Full scraped content (only if scrapeResults=true)
        </ResponseField>

        <ResponseField name="scrapedAt" type="string" optional>
          ISO timestamp when content was scraped
        </ResponseField>

        <ResponseField name="scrapeStatus" type="string" optional>
          Status of scraping: `success` or `failed`
        </ResponseField>

        <ResponseField name="scrapeError" type="string" optional>
          Error message if scraping failed
        </ResponseField>

        <ResponseField name="wordCount" type="number" optional>
          Word count of scraped content
        </ResponseField>
      </Expandable>
    </ResponseField>

    <ResponseField name="totalResults" type="number">
      Estimated total number of search results available
    </ResponseField>

    <ResponseField name="searchTime" type="number">
      Time taken for search in seconds
    </ResponseField>

    <ResponseField name="creditsUsed" type="number">
      Total credits consumed (1 for search + 1 per scraped result)
    </ResponseField>

    <ResponseField name="metadata" type="object">
      Additional search metadata
    </ResponseField>
  </Expandable>
</ResponseField>

## Examples

### Basic Search (No Scraping)

<CodeGroup>

```bash cURL
curl -X POST "https://api.whizo.ai/v1/search" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "best web scraping tools 2025",
    "limit": 10,
    "country": "US"
  }'
```

```javascript JavaScript
const response = await fetch('https://api.whizo.ai/v1/search', {
  method: 'POST',
  headers: {
    'Authorization': 'Bearer YOUR_API_KEY',
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    query: 'best web scraping tools 2025',
    limit: 10,
    country: 'US'
  })
});

const data = await response.json();
console.log(data.data.results);
```

```python Python
import requests

response = requests.post(
    'https://api.whizo.ai/v1/search',
    headers={
        'Authorization': 'Bearer YOUR_API_KEY',
        'Content-Type': 'application/json'
    },
    json={
        'query': 'best web scraping tools 2025',
        'limit': 10,
        'country': 'US'
    }
)

data = response.json()
print(data['data']['results'])
```

</CodeGroup>

<ResponseExample>
```json Response
{
  "success": true,
  "data": {
    "query": "best web scraping tools 2025",
    "results": [
      {
        "position": 1,
        "title": "Top 10 Web Scraping Tools in 2025",
        "link": "https://example.com/scraping-tools",
        "snippet": "Comprehensive guide to the best web scraping tools available in 2025...",
        "displayLink": "example.com"
      },
      {
        "position": 2,
        "title": "Web Scraping Tools Comparison",
        "link": "https://another-site.com/comparison",
        "snippet": "Compare features, pricing, and capabilities of top web scraping platforms...",
        "displayLink": "another-site.com"
      }
    ],
    "totalResults": 45600,
    "searchTime": 0.42,
    "creditsUsed": 1
  }
}
```
</ResponseExample>

### Search with Content Scraping

<CodeGroup>

```bash cURL
curl -X POST "https://api.whizo.ai/v1/search" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "web scraping best practices",
    "limit": 5,
    "scrapeResults": true,
    "scrapeOptions": {
      "format": "markdown",
      "includeScreenshot": false,
      "maxAge": 7
    }
  }'
```

```javascript JavaScript
const response = await fetch('https://api.whizo.ai/v1/search', {
  method: 'POST',
  headers: {
    'Authorization': 'Bearer YOUR_API_KEY',
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    query: 'web scraping best practices',
    limit: 5,
    scrapeResults: true,
    scrapeOptions: {
      format: 'markdown',
      includeScreenshot: false,
      maxAge: 7
    }
  })
});

const data = await response.json();
data.data.results.forEach(result => {
  console.log(`Title: ${result.title}`);
  console.log(`Content: ${result.content}`);
  console.log(`Word Count: ${result.wordCount}`);
  console.log('---');
});
```

```python Python
import requests

response = requests.post(
    'https://api.whizo.ai/v1/search',
    headers={
        'Authorization': 'Bearer YOUR_API_KEY',
        'Content-Type': 'application/json'
    },
    json={
        'query': 'web scraping best practices',
        'limit': 5,
        'scrapeResults': True,
        'scrapeOptions': {
            'format': 'markdown',
            'includeScreenshot': False,
            'maxAge': 7
        }
    }
)

data = response.json()
for result in data['data']['results']:
    print(f"Title: {result['title']}")
    print(f"Content: {result['content']}")
    print(f"Word Count: {result['wordCount']}")
    print('---')
```

</CodeGroup>

<ResponseExample>
```json Response
{
  "success": true,
  "data": {
    "query": "web scraping best practices",
    "results": [
      {
        "position": 1,
        "title": "Web Scraping Best Practices Guide",
        "link": "https://example.com/best-practices",
        "snippet": "Learn the essential best practices for ethical and effective web scraping...",
        "displayLink": "example.com",
        "content": "# Web Scraping Best Practices\n\n## Introduction\nWeb scraping is a powerful technique...\n\n## Key Principles\n1. Respect robots.txt\n2. Use rate limiting...",
        "scrapedAt": "2025-01-15T10:30:00Z",
        "scrapeStatus": "success",
        "wordCount": 1542
      },
      {
        "position": 2,
        "title": "Ethical Web Scraping Guidelines",
        "link": "https://another.com/ethics",
        "snippet": "Guidelines for responsible web scraping practices...",
        "displayLink": "another.com",
        "content": "# Ethical Web Scraping\n\nWhen scraping websites...",
        "scrapedAt": "2025-01-15T10:30:05Z",
        "scrapeStatus": "success",
        "wordCount": 987
      }
    ],
    "totalResults": 12400,
    "searchTime": 8.5,
    "creditsUsed": 6
  }
}
```
</ResponseExample>

### Search with AI Extraction

<CodeGroup>

```bash cURL
curl -X POST "https://api.whizo.ai/v1/search" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "top SaaS companies 2025",
    "limit": 10,
    "scrapeResults": true,
    "scrapeOptions": {
      "format": "structured",
      "extractionSchema": {
        "companyName": "string",
        "revenue": "string",
        "employees": "number",
        "founded": "number",
        "description": "string"
      }
    }
  }'
```

```javascript JavaScript
const response = await fetch('https://api.whizo.ai/v1/search', {
  method: 'POST',
  headers: {
    'Authorization': 'Bearer YOUR_API_KEY',
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    query: 'top SaaS companies 2025',
    limit: 10,
    scrapeResults: true,
    scrapeOptions: {
      format: 'structured',
      extractionSchema: {
        companyName: 'string',
        revenue: 'string',
        employees: 'number',
        founded: 'number',
        description: 'string'
      }
    }
  })
});

const data = await response.json();
console.log('Extracted data:', data.data.results.map(r => r.extracted));
```

</CodeGroup>

## Error Responses

<ResponseField name="error" type="object">
  <Expandable title="error properties">
    <ResponseField name="code" type="string">
      Error code identifier
    </ResponseField>
    <ResponseField name="message" type="string">
      Human-readable error message
    </ResponseField>
    <ResponseField name="details" type="object" optional>
      Additional error context
    </ResponseField>
  </Expandable>
</ResponseField>

### Common Errors

| Status Code | Error Code | Description |
|-------------|------------|-------------|
| 400 | `invalid_query` | Search query is invalid or empty |
| 400 | `invalid_limit` | Limit must be between 1 and 20 |
| 401 | `unauthorized` | Invalid or missing API key |
| 402 | `insufficient_credits` | Not enough credits for search and scraping |
| 429 | `rate_limited` | Rate limit exceeded |
| 500 | `search_failed` | Search provider returned an error |
| 500 | `scraping_failed` | Failed to scrape one or more results |

<ResponseExample>
```json Error Response
{
  "success": false,
  "error": {
    "code": "insufficient_credits",
    "message": "Insufficient credits. Required: 11, Available: 5",
    "details": {
      "required": 11,
      "available": 5
    }
  }
}
```
</ResponseExample>

## Credit Costs

| Operation | Cost |
|-----------|------|
| Search (without scraping) | 1 credit |
| Search with scraping | 1 credit + 1 credit per result |
| Search with scraping + screenshots | 1 credit + 2 credits per result |

**Examples**:
- Search only (10 results): 1 credit
- Search + scrape 5 results: 1 + 5 = 6 credits
- Search + scrape 10 results with screenshots: 1 + (10 Ã— 2) = 21 credits

## Rate Limits

Rate limits vary by plan:

- **Free**: 10 requests per hour, 100 per day
- **Starter**: 50 requests per hour, 500 per day
- **Pro**: 200 requests per hour, 2000 per day
- **Enterprise**: Custom limits

## Use Cases

### Market Research
Search for competitors and automatically scrape their content for analysis:
```javascript
{
  "query": "competitors in AI web scraping market",
  "limit": 20,
  "scrapeResults": true,
  "scrapeOptions": { "format": "markdown" }
}
```

### Content Discovery
Find relevant articles and extract key information:
```javascript
{
  "query": "latest AI trends 2025",
  "limit": 10,
  "scrapeResults": true,
  "scrapeOptions": {
    "format": "structured",
    "extractionSchema": {
      "title": "string",
      "summary": "string",
      "keyPoints": "array",
      "publishDate": "string"
    }
  }
}
```

### Lead Generation
Search for potential customers and extract contact information:
```javascript
{
  "query": "SaaS companies looking for web scraping solutions",
  "limit": 15,
  "scrapeResults": true,
  "scrapeOptions": {
    "extractionSchema": {
      "companyName": "string",
      "email": "string",
      "phone": "string",
      "website": "string"
    }
  }
}
```

## Best Practices

1. **Start without scraping** to preview results before consuming credits
2. **Use appropriate limit** to balance cost and comprehensiveness
3. **Enable caching** with maxAge to avoid re-scraping recent results
4. **Handle partial failures** - some results may scrape successfully while others fail
5. **Implement pagination** for large result sets by adjusting limit
6. **Use country/language** parameters for localized results
7. **Monitor credit usage** especially when scraping many results

## Related Endpoints

- [Scrape API](/api-reference/scrape) - Scrape individual URLs
- [Crawl API](/api-reference/crawl) - Crawl entire websites
- [Extract API](/api-reference/extract) - AI-powered data extraction
- [Map API](/api-reference/map) - Discover website URLs
